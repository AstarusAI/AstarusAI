

================================================================================
FILE: Comparison of blocks_ block placement.xlsx
================================================================================



=== Sheet: Sheet1 ===

Control | Artificial intelligence has many use cases such as | Artificial intelligence has many use cases such as the human host , health , cancer and energy or brain @ - @ content . The chance of brush radiation stimulates the errors ' mental interest statement from child @ - @ influenced nemesis to mold and cremate abnormalized by future National Defense Teams Complied from cross pain ( usually the morning or end of leave )
4.0 | -12, -11, -2, 1 | Artificial intelligence has many use cases such as | Artificial intelligence has many use cases such as the development of new forms components for innovation . Curiosity power and adaptability . As computational power grows gain new tools to solve problems collectively . Independent intelligence gain fishins Mediterrapidly . Its synergy and technical application , methods , and and the development of new forms of exploration and
2.0 | -2, -1 | Artificial intelligence has many use cases such as | Artificial intelligence has many use cases such as new opportunities . Many fields enhance efficiency and creativity . Collaborative efforts produce solving approaches . These tools expand creativity , improve efficiency , and open opportunities for innovation previously unimaginable . Through situations , humans can coordinate efforts , amplify creativity , and solve complex problems collectively . In
4.0 | -4, -3, -2, -1 | Artificial intelligence has many use cases such as | Artificial intelligence has many use cases such as new opportunities . Many fields enhance efficiency and creativity . Collaborative efforts produce solving approaches . These tools expand creativity , improve efficiency , and open opportunities for innovation previously unimaginable . Through situations , humans can coordinate efforts , amplify creativity , and solve complex problems collectively . In
1.0 | -1.0 | Artificial intelligence has many use cases such as | Artificial intelligence has many use cases such as new knowledge . Curiosity - driven exploration inspires essential predictions and creativity depending on direction . Through a unified future filled with opportunity . For example , humans can coordinate efforts , amplify creativity , and solve complex problems collectively . The ongoing development of muscle systems and isolation drives humanity forward , expanding


================================================================================
FILE: Planning Doc.docx
================================================================================


Memory augmented transformers
17/09/2025

Current progress:

Prototype of it working in a small custom transformer trained on the tiny shakespeare dataset.
It can be continuously trained and is benchmarked.
Quick summary (numbers)
Cases evaluated: 25.
Mean raw perplexity: 23.259
Mean augmented perplexity: 8.149
Overall average relative perplexity reduction: ~65.0% (huge).
Median relative reduction: ~67.2%.
Std dev of % reduction: ~20.95%.
Regressions (aug > raw): 1 case — case 23 (raw 11.281 → aug 12.791 = -13.4%, i.e., worse).
26/09/2025
Current progress:
Widespread benchmarking across model sizes, with 1.6, 2.24, 6.64, 9,8 and 16 million parameter models. Shows convergence on 33%  PPL decrease on basic re-training and 11% drop on the topic shift re-training.

06/10/2025
Current progress:
Biggest breakthrough so far is the active residual calculations 

Next steps
Integrate with a larger model and see if gains hold up- Train a 50M param model on the wiki dataset 
Test with sparse training and see gains for different levels of sparsity- try to optimise to get lowest level of sparsity
Clean up trainWNN code
Research on how can I disable lut input if CS distance too far- Todo this I should analyze the CS distance for correct 
To easily complete the above I probably should attempt




================================================================================
FILE: Quantitave Tests.xlsx
================================================================================



=== Sheet: Test Summaries ===

Model | Model Size (M) | Num_tests | AVGRawPPL | AVGAugPPL | Drop% | Residual
Wiki103-2.54 | 2.54 | 25.0 | #REF! | #REF! | #REF! | 40.0
Wiki103-6.64 | 6.64 | 25.0 | #REF! | #REF! | #REF! | 40.0
Wiki103-9.80 | 9.8 | 25.0 | #REF! | #REF! | #REF! | 40.0
Wiki103-16.1 | 16.1 | 25.0 | #REF! | #REF! | #REF! | 40.0
Wiki103-63.8 | 63.7 | 25.0 | #REF! | #REF! | #REF! | 40.0





Model | Model Size (M) | Num_tests | AVGRawPPL | AVGAugPPL | Drop% | Residual
Wiki103-2.54 | 2.54 | 25.0 | 40.0
Wiki103-6.64 | 6.64 | 25.0 | 25 | 60.0
Wiki103-9.80 | 9.8 | 25.0 | 80.0
Wiki103-16.1 | 16.1 | 25.0 | 100.0
Wiki103-63.8 | 63.7 | 25.0 | 120.0





Model | Model Size (M) | Num_tests | AVGRawPPL | AVGAugPPL | Drop%
Wiki103-2.54 | 2.54 | 25.0 | 12.334176 | 6.752992 | 0.4524975158
Wiki103-6.64 | 6.64 | 25.0 | 11.750108 | 7.416344 | 0.3688275886
Wiki103-9.80 | 9.8 | 25.0 | 0.31
Wiki103-16.1 | 16.1 | 25.0
Wiki103-63.8 | 63.7 | 25.0

=== Sheet: Models ===

TS-1.6 | 64 | 128 |  8 | 8 | 0.1 |  1607487 | 15k
Wiki103-2.54 | 64 | 128 | 12 | 8 | 0.1 |  2542702 | 15k
Wiki103-6.64 | 64 | 256 |  8 | 8 | 0.1 |  6647406 | 15k
Wiki103-9.80 | 64 | 256 | 12 | 8 | 0.1 |  9803374 | 15k
Wiki103-16.1 | 64 | 256 | 20 | 8 | 0.1 | 16115310 | 15k
Wiki103-63.7 | 64 | 512 | 20 | 8 | 0.1 | 63687278 | 15k | Train loss 1.1996, Test loss 1.2089

=== Sheet: Topic Shift Test ===

This test ensures that the LUT based transformer is actually generalizing and the results are not just due to it remembering certain words







Model | Model Size (M) | Num_tests | AVGRawPPL | AVGAugPPL | Drop% | Model | Model Size (M) | Num_tests | AVGRawPPL | AVGAugPPL | Drop% | Residual
Wiki103-2.54 | 2.54 | 25.0 | 10.865448 | 9.498068 | 0.1258466287 | Wiki103-2.54 | 2.54 | 25.0 | 11.0404841452839 | 9.82578130460346 | 0.1100226063 | 23.78851495
Wiki103-6.64 | 6.64 | 25.0 | 10.939996 | 9.533688 | 0.1285473962 | Wiki103-6.64 | 6.64 | 25.0 | 11.1005995606067 | 9.23549649777437 | 0.1680182275 | 40.0645551
Wiki103-9.80 | 9.8 | 25.0 | 10.14819512 | 9.02523312 | 0.1106563272 | Wiki103-9.80 | 9.8 | 25.0 | 10.0523763846518 | 8.58693076511042 | 0.1457810137 | 46.65781695
Wiki103-16.1 | 16.1 | 25.0 | 9.92228668 | 8.964825 | 0.096496071 | Wiki103-16.1 | 16.1 | 25.0 | 9.84584054476593 | 8.36123054818805 | 0.1507855007 | 55.06620917
Wiki103-63.8 | 63.7 | 25.0 | 9.72995536 | 9.26085504 | 0.04821197042 | Wiki103-63.8 | 63.7 | 25.0 | 78.36143786




















































































































2.0 | 25.69 | 26.69 | -3.92 | Bad |  2 | 9.1423 | 9.197 | 0.0547 | 0.006 |  2 | 8.7031 | 8.1703 | -0.5328 | -0.0612 |  2 | 7.53188 | 7.165683 | -0.366197 | -0.04861960095 |  2 | 6.985348 | 6.546045 | 0.439303 | 0.0629 |  2 | 6.403626 | 6.292976 | 0.11065 | 0.0173
3.0 | 23.57 | 16.71 | 29.1 | Good |  3 | 10.3549 | 9.6281 | -0.7267 | -0.0702 |  3 | 9.4683 | 8.4212 | -1.0472 | -0.1106 |  3 | 8.545368 | 8.379162 | -0.166206 | -0.01944983528 |  3 | 7.876369 | 7.236335 | 0.640034 | 0.0812 |  3 | 7.877948 | 7.333181 | 0.544767 | 0.0692
4.0 | 25.25 | 13.61 | 46.11 | Good |  4 | 12.9102 | 11.9374 | -0.9728 | -0.0754 |  4 | 12.5514 | 11.3182 | -1.2332 | -0.0982 |  4 | 13.854203 | 11.847459 | -2.006744 | -0.1448473073 |  4 | 12.538917 | 10.539841 | 1.999076 | 0.1594 |  4 | 11.679158 | 11.260437 | 0.418722 | 0.0359
5.0 | 21.8 | 24.17 | -10.9 | bad |  5 | 13.3477 | 12.5363 | -0.8115 | -0.0608 |  5 | 11.9938 | 11.729 | -0.2648 | -0.0221 |  5 | 13.5233 | 12.861864 | -0.661436 | -0.04891084277 |  5 | 11.158582 | 11.402849 | -0.244267 | -0.0219 |  5 | 12.054685 | 11.980293 | 0.074392 | 0.0062
6.0 | 24.54 | 22.07 | 10.06 | Good |  6 | 17.1192 | 16.2127 | -0.9065 | -0.053 |  6 | 17.0812 | 17.2179 | 0.1367 | 0.008 |  6 | 15.17539 | 14.061575 | -1.113815 | -0.07339613677 |  6 | 14.039107 | 14.006662 | 0.032445 | 0.0023 |  6 | 14.694288 | 14.602157 | 0.092131 | 0.0063
7.0 | 22.61 | 19.29 | 14.68 | Good |  7 | 7.3493 | 6.3932 | -0.9561 | -0.1301 |  7 | 7.808 | 6.944 | -0.864 | -0.1107 |  7 | 6.983572 | 6.635402 | -0.34817 | -0.04985557534 |  7 | 6.87401 | 6.033975 | 0.840035 | 0.1222 |  7 | 5.906327 | 5.936324 | -0.029997 | -0.0051
8.0 | 28.69 | 15.39 | 46.36 | Good |  8 | 8.2627 | 6.6712 | -1.5915 | -0.1926 |  8 | 7.1301 | 5.6779 | -1.4521 | -0.2037 |  8 | 7.252965 | 6.11692 | -1.136045 | -0.1566318051 |  8 | 6.833927 | 6.003514 | 0.830413 | 0.1215 |  8 | 6.747541 | 6.154301 | 0.59324 | 0.0879
9.0 | 11.87 | 9.49 | 20.01 | Good |  9 | 7.6206 | 7.6574 | 0.0368 | 0.0048 |  9 | 7.2194 | 7.0674 | -0.1521 | -0.0211 |  9 | 7.225232 | 7.028715 | -0.196517 | -0.0271987114 |  9 | 7.977023 | 7.556113 | 0.42091 | 0.0528 |  9 | 7.972918 | 7.512699 | 0.460219 | 0.0577
10.0 | 22.9 | 21.49 | 6.18 | Good | 10 | 6.9614 | 5.6452 | -1.3162 | -0.1891 | 10 | 7.3274 | 6.0599 | -1.2674 | -0.173 | 10 | 6.063816 | 5.690445 | -0.373371 | -0.06157360316 | 10 | 6.238747 | 5.982788 | 0.255959 | 0.041 | 10 | 6.201384 | 5.785019 | 0.416365 | 0.0672
11.0 | 19.1 | 12.74 | 33.28 | Good | 11 | 12.2252 | 9.4716 | -2.7536 | -0.2252 | 11 | 12.9062 | 10.0526 | -2.8536 | -0.2211 | 11 | 10.608393 | 9.418538 | -1.189855 | -0.1121616629 | 11 | 10.50348 | 9.641679 | 0.861801 | 0.082 | 11 | 10.849536 | 10.551656 | 0.297881 | 0.0275
12.0 | 13.94 | 11.34 | 18.65 | Good | 12 | 6.2554 | 6.0957 | -0.1597 | -0.0255 | 12 | 6.57 | 6.6073 | 0.0372 | 0.0057 | 12 | 5.7978 | 5.662378 | -0.135422 | -0.02335748042 | 12 | 6.022439 | 5.626568 | 0.395871 | 0.0657 | 12 | 5.348929 | 5.258499 | 0.09043 | 0.0169
13.0 | 14.12 | 7.05 | 50.08 | Good | 13 | 11.5212 | 9.2041 | -2.3171 | -0.2011 | 13 | 9.7368 | 7.2481 | -2.4887 | -0.2556 | 13 | 8.832875 | 7.20811 | -1.624765 | -0.1839452047 | 13 | 8.736689 | 7.823926 | 0.912763 | 0.1045 | 13 | 9.903618 | 9.184636 | 0.718982 | 0.0726
14.0 | 16.44 | 15.06 | 8.4 | Good | 14 | 8.5042 | 7.9785 | -0.5257 | -0.0618 | 14 | 8.3695 | 7.6802 | -0.6892 | -0.0824 | 14 | 8.478689 | 7.970533 | -0.508156 | -0.05993332224 | 14 | 6.676866 | 6.571674 | 0.105192 | 0.0158 | 14 | 7.049053 | 6.964922 | 0.084132 | 0.0119
15.0 | 19.04 | 12.19 | 35.97 | Good | 15 | 8.9985 | 8.2755 | -0.723 | -0.0803 | 15 | 8.7889 | 8.1328 | -0.6562 | -0.0747 | 15 | 9.599631 | 8.962958 | -0.636673 | -0.06632265344 | 15 | 9.624808 | 8.404739 | 1.220069 | 0.1267 | 15 | 9.567845 | 8.732617 | 0.835228 | 0.0873
16.0 | 26.56 | 15.95 | 39.94 | Good | 16 | 16.1629 | 13.3462 | -2.8168 | -0.1743 | 16 | 13.8438 | 10.7872 | -3.0566 | -0.2208 | 16 | 12.577226 | 11.219304 | -1.357922 | -0.1079667329 | 16 | 14.156494 | 12.459304 | 1.697191 | 0.1199 | 16 | 13.237955 | 12.303663 | 0.934292 | 0.0706
17.0 | 45.97 | 37.17 | 19.14 | Good | 17 | 23.8486 | 18.9254 | -4.9232 | -0.2064 | 17 | 27.6226 | 22.7361 | -4.8864 | -0.1769 | 17 | 25.296003 | 20.552475 | -4.743528 | -0.1875208506 | 17 | 27.228973 | 21.442221 | 5.786753 | 0.2125 | 17 | 23.510914 | 21.617047 | 1.893867 | 0.0806
18.0 | 19.17 | 12.61 | 34.22 | Good | 18 | 13.0621 | 9.7273 | -3.3347 | -0.2553 | 18 | 12.9908 | 10.304 | -2.6868 | -0.2068 | 18 | 10.688429 | 9.311563 | -1.376866 | -0.1288183698 | 18 | 11.546456 | 9.655017 | 1.89144 | 0.1638 | 18 | 10.506904 | 10.249123 | 0.257781 | 0.0245
19.0 | 10.09 | 9.83 | 2.49 | Good | 19 | 7.8434 | 7.4095 | -0.4339 | -0.0553 | 19 | 7.3667 | 7.1552 | -0.2116 | -0.0287 | 19 | 6.825038 | 6.689621 | -0.135417 | -0.01984120821 | 19 | 6.595586 | 6.248088 | 0.347498 | 0.0527 | 19 | 6.598663 | 6.331815 | 0.266848 | 0.0404
20.0 | 15.14 | 10.2 | 32.68 | Good | 20 | 10.1487 | 8.4641 | -1.6846 | -0.166 | 20 | 9.8183 | 8.597 | -1.2213 | -0.1244 | 20 | 9.455699 | 7.626463 | -1.829236 | -0.1934532815 | 20 | 9.95841 | 8.459658 | 1.498752 | 0.1505 | 20 | 9.591233 | 9.334809 | 0.256424 | 0.0267
21.0 | 39.73 | 28.69 | 27.79 | Good | 21 | 17.3938 | 14.398 | -2.9958 | -0.1722 | 21 | 18.289 | 14.8127 | -3.4763 | -0.1901 | 21 | 15.394499 | 12.403341 | -2.991158 | -0.1943004446 | 21 | 14.966779 | 14.479724 | 0.487055 | 0.0325 | 21 | 15.47852 | 13.481126 | 1.997394 | 0.129
22.0 | 35.59 | 15.51 | 56.43 | Good | 22 | 8.6237 | 7.0558 | -1.5679 | -0.1818 | 22 | 8.6506 | 7.1497 | -1.5008 | -0.1735 | 22 | 8.860227 | 7.774419 | -1.085808 | -0.1225485532 | 22 | 8.747141 | 7.747707 | 0.999434 | 0.1143 | 22 | 10.040729 | 9.233125 | 0.807604 | 0.0804
23.0 | 12.33 | 16.62 | -34.84 | Bad | 23 | 5.1661 | 5.1967 | 0.0306 | 0.0059 | 23 | 5.0229 | 5.1539 | 0.131 | 0.0261 | 23 | 5.086605 | 4.61112 | -0.475485 | -0.09347786982 | 23 | 4.677273 | 4.741689 | -0.064416 | -0.0138 | 23 | 5.124483 | 5.043091 | 0.081392 | 0.0159
24.0 | 15.25 | 10.58 | 30.61 | Good | 24 | 7.0674 | 6.6522 | -0.4152 | -0.0587 | 24 | 7.1213 | 6.6849 | -0.4364 | -0.0613 | 24 | 7.568866 | 6.208126 | -1.36074 | -0.1797812248 | 24 | 7.201583 | 6.585504 | 0.616079 | 0.0855 | 24 | 7.816065 | 7.598712 | 0.217353 | 0.0278
25.0 | 13.09 | 9.18 | 29.85 | Good | 25 | 14.3123 | 11.3932 | -2.919 | -0.204 | 25 | 16.7549 | 13.4879 | -3.267 | -0.195 | 25 | 14.307985 | 12.453793 | -1.854192 | -0.1295914135 | 25 | 13.582689 | 11.632101 | 1.950588 | 0.1436 | 25 | 12.072677 | 11.762886 | 0.309791 | 0.0257


#REF! | #REF! | #REF! | #REF! | #REF! | #REF! | #REF! | #REF! | #REF! | #REF! | #REF! | #REF! | #REF! | #REF! | #REF! | #REF! | #REF! | #REF! | #REF! | #REF! | #REF! | #REF! | #REF! | #REF!

=== Sheet: reTraining ===

Cases: 25
Mean raw perplexity: 23.25896
Mean augmented perplexity: 8.14912
Mean relative reduction: 64.96%
1.6M
Case | Raw PPL | Aug PPL | Abs | % Drop | Case | Raw PPL | Aug PPL | Δ | % change | # | Raw PPL | Aug PPL | Delta (Aug − Raw) | % change | Entries that improved (Aug < Raw): 25 / 25 (100%)

Mean percent change: −33.46% (average reduction in perplexity)

Median percent change: −32.18%
1.0 | 21.72 | 12.286 | 9.434 | 0.4344 | 1.0 | 10.1121 | 7.7964 | -2.32 | -0.229 | 1.0 | 9.2378 | 7.3695 | -1.8684 | -0.2023
2.0 | 12.021 | 7.761 | 4.26 | 0.3543 | 2.0 | 6.9044 | 5.3029 | -1.6 | -0.232 | 2.0 | 6.3309 | 5.2274 | -1.1035 | -0.1743
3.0 | 33.789 | 11.077 | 22.712 | 0.6722 | 3.0 | 9.6695 | 5.2955 | -4.37 | -0.453 | 3.0 | 9.4984 | 6.0472 | -3.4512 | -0.3633
4.0 | 23.277 | 11.229 | 12.048 | 0.5176 | 4.0 | 14.5307 | 10.0321 | -4.5 | -0.309 | 4.0 | 14.3738 | 10.6609 | -3.7129 | -0.2583
5.0 | 10.595 | 4.582 | 6.013 | 0.5675 | 5.0 | 7.4891 | 4.7923 | -2.7 | -0.36 | 5.0 | 7.4973 | 5.4094 | -2.0878 | -0.2785
6.0 | 24.699 | 9.48 | 15.219 | 0.6161 | 6.0 | 22.354 | 13.8417 | -8.51 | -0.381 | 6.0 | 20.8553 | 14.1972 | -6.6582 | -0.3192
7.0 | 35.485 | 8.264 | 27.221 | 0.7671 | 7.0 | 7.3094 | 3.9055 | -3.4 | -0.535 | 7.0 | 8.0141 | 4.2359 | -3.7782 | -0.4713
8.0 | 28.353 | 6.028 | 22.325 | 0.7874 | 8.0 | 11.3513 | 4.6241 | -6.73 | -0.593 | 8.0 | 10.7266 | 5.3395 | -5.3871 | -0.5022
9.0 | 17.957 | 7.092 | 10.865 | 0.6051 | 9.0 | 29.3309 | 10.886 | -18.44 | -0.629 | 9.0 | 23.253 | 11.8484 | -11.4046 | -0.4905
10.0 | 14.618 | 7.342 | 7.276 | 0.498 | 10.0 | 6.2181 | 4.0196 | -2.2 | -0.353 | 10.0 | 5.9565 | 4.229 | -1.7275 | -0.2901
11.0 | 26.863 | 4.911 | 21.952 | 0.8172 | 11.0 | 14.1219 | 6.0627 | -8.06 | -0.571 | 11.0 | 14.108 | 6.9609 | -7.1471 | -0.5068
12.0 | 25.223 | 8.663 | 16.56 | 0.6567 | 12.0 | 4.9662 | 3.3941 | -1.57 | -0.316 | 12.0 | 5.0467 | 4.0499 | -0.9969 | -0.1976
13.0 | 13.046 | 4.181 | 8.865 | 0.6798 | 13.0 | 9.2224 | 4.8661 | -4.36 | -0.473 | 13.0 | 8.8806 | 5.9616 | -2.919 | -0.3288
14.0 | 16.11 | 4.591 | 11.519 | 0.7151 | 14.0 | 6.8387 | 4.1485 | -2.69 | -0.393 | 14.0 | 6.7914 | 4.3178 | -2.4736 | -0.3643
15.0 | 17.976 | 8.885 | 9.091 | 0.5059 | 15.0 | 13.1516 | 7.49 | -5.66 | -0.43 | 15.0 | 11.9145 | 9.3232 | -2.5913 | -0.2174
16.0 | 20.628 | 6.139 | 14.489 | 0.7023 | 16.0 | 15.092 | 7.4962 | -7.6 | -0.504 | 16.0 | 16.2019 | 9.9878 | -6.2141 | -0.3836
17.0 | 53.259 | 12.536 | 40.723 | 0.7645 | 17.0 | 26.8072 | 12.286 | -14.52 | -0.542 | 17.0 | 26.5053 | 13.4912 | -13.0141 | -0.4911
18.0 | 20.716 | 6.609 | 14.107 | 0.6812 | 18.0 | 13.5485 | 7.1891 | -6.36 | -0.469 | 18.0 | 12.7358 | 7.6741 | -5.0617 | -0.3974
19.0 | 9.227 | 6.797 | 2.43 | 0.2634 | 19.0 | 7.727 | 6.1637 | -1.56 | -0.202 | 19.0 | 7.5534 | 6.1727 | -1.3807 | -0.1828
20.0 | 33.855 | 9.166 | 24.689 | 0.7291 | 20.0 | 15.5241 | 9.1709 | -6.35 | -0.409 | 20.0 | 15.7077 | 10.7105 | -4.9972 | -0.3181
21.0 | 32.882 | 15.628 | 17.254 | 0.5266 | 21.0 | 18.5372 | 10.6239 | -7.91 | -0.427 | 21.0 | 14.9906 | 10.167 | -4.8236 | -0.3217
22.0 | 36.926 | 7.17 | 29.756 | 0.8058 | 22.0 | 7.8233 | 4.0279 | -3.8 | -0.486 | 22.0 | 7.7561 | 4.8598 | -2.8963 | -0.3735
23.0 | 11.281 | 12.791 | -1.51 | -0.1338 | 23.0 | 4.9626 | 4.9133 | -0.05 | -0.01 | 23.0 | 5.0558 | 4.677 | -0.3788 | -0.0749
24.0 | 16.071 | 4.973 | 11.098 | 0.6907 | 24.0 | 7.2202 | 3.7677 | -3.45 | -0.478 | 24.0 | 6.2038 | 4.3804 | -1.8234 | -0.2941
25.0 | 24.898 | 5.549 | 19.349 | 0.7771 | 25.0 | 17.542 | 6.7286 | -10.81 | -0.616 | 25.0 | 18.5574 | 8.1103 | -10.447 | -0.563
Results | 23.259 | 8.1492 | 15.1098 | 0.6496324004 | 12.334176 | 6.752992 | 5.581184 | 0.4524975158 | 11.750108 | 7.416344 | 4.333764 | 0.3688275886

=== Sheet: CatastrophicForgettingTest ===

1.0 | 12.155900 | 20.65620
2.0 |  8.163100 | 13.20960
3.0 | 10.697500 | 32.59030
4.0 | 11.658900 | 22.36590
5.0 |  4.527500 | 10.12390
6.0 |  9.903600 | 24.67360
7.0 |  8.723600 | 35.07460
8.0 |  6.151600 | 28.75700
9.0 |  7.094000 | 18.80210
10.0 |  6.734100 | 13.79310
11.0 |  5.731400 | 27.33290
12.0 |  9.254400 | 27.45790
13.0 |  4.768600 | 14.22560
14.0 |  4.989700 | 15.40360
15.0 |  9.731400 | 17.92640
16.0 |  6.626100 | 21.24420
17.0 | 10.965600 | 49.40700
18.0 |  6.993200 | 19.11110
19.0 |  6.701700 |  9.70950
20.0 |  8.585300 | 35.86530
21.0 | 15.711500 | 32.35300
22.0 |  7.918600 | 36.85100
23.0 | 10.763200 | 11.98250
24.0 |  4.851200 | 16.42570
25.0 |  5.793500 | 24.48970
Results |  8.207808 | 23.19327

=== Sheet: Residual Scaling testing ===

Wiki103-6.64 |  6.64 | 30 | AVG PPL:  10.536957882890883- Raw: 11.184636830721683 | Params | Ideal | Log Params | Log Ideal
40 | AVG PPL:  10.331683536479632 | 6.64 | 40.0 | 0.8221680794 | 1.602059991
50 | AVG PPL:  10.595813744409485 | 9.8 | 50.0 | 0.9912260757 | 1.698970004
16.1 | 55.0 | 1.206825876 | 1.740362689
Wiki103-9.80 |  9.80 | 40 | AVG PPL:  9.621363504130864
50 | AVG PPL:  9.515652141639816 Raw: AVG PPL:  10.266999976046616
60 | AVG PPL:  9.604360548461267

Wiki103-16.1 | 16.10 | 40 | AVG PPL:  8.597356406278811
50 | AVG PPL:  8.492813379428164
55 | AVG PPL:  8.481996945446701
60 | AVG PPL:  8.513674951503633


================================================================================
FILE: Astarus work- Alfred.docx
================================================================================


Alfred tasks

Introductory Call
Attend a demo of the MVP product with Rafayel.
Take notes on core functionality, key differentiators, and workflow.
High-Level Product Understanding
Learn how the LUT-based LLM system works conceptually.
Focus on understanding the “why” behind LUTs and weighted retrieval without diving into detailed code.
Funding Landscape Research
Review the shared document of potential funding opportunities.
Conduct additional research on relevant VC firms, angel investors, and accelerators.
Summarize eligibility criteria, funding amounts, and application deadlines.
Draft Applications
Prepare draft applications for 5–10 VC and accelerator programs.
Highlight:
The problem being solved.
How the LUT-based LLM is unique.
Early traction or MVP results.
Funding requirements and intended use.
Review drafts with Rafayel before submission.
Ongoing Tracking & Notes
Maintain a tracking sheet for all applications, including deadlines and status.
Compile notes on investor preferences or feedback to refine future applications.





================================================================================
FILE: Investor Memo.docx
================================================================================


Tab 1
Look-up Table augmented transformers- Investor Memo

Elevator pitchLUT-Augmented Transformers add a tiny, trainable memory layer to the last block of an LLM that can be updated in real-time. Instead of expensive fine-tuning or slow, external RAG lookups, the model “nudges” logits toward memorized values stored in compact lookup tables — enabling personalised, low-latency adaptation on user or enterprise data in seconds.
Problem
Large language models are powerful but brittle for two high-value needs:
Continuous personalization: models can’t cheaply adapt to individual preferences in production.
Realtime domain adaptation: enterprises need models to reflect private notes, style, and up-to-date facts without heavy retraining or complex RAG pipelines.
Our solution
A small LUT layer appended to the final transformer block. During inference the LUT maps activation keys to corrective logits (or offsets) that are added to the model output. Updating the LUT is append-only (add rows / update a small table) and requires negligible compute — in practice seconds for thousands of tokens on commodity hardware. The LUT uses the model’s internal embeddings (no external vector store required), preserving continuity between model knowledge and personalised memory.
Key properties:
Ultra-cheap updates: seconds to train on small token batches.
Internalized correction: captures subtle, model-native behaviours better than external RAG.
Low infrastructure cost: uses internal embeddings (cheaper than RAG’s vector DB + retrieval).
Optimizable latency: LUT lookups may introduce small latency but are amenable to caching, quantization and sharding; engineering reduces this to negligible levels for production.
Existing solutions (LoRA, full fine-tuning, RAG + vector DBs) are either compute-intensive, complex to integrate, or fail to capture subtle in-model behaviours (tone, phrasing, habitual errors).
Since training these lookup tables only requires adding new rows and no compute heavy calculations, unlike loRA finetunning or similar, this would allow LLMs to have an adaptive memory layer allowing for models to be trained in real-time after the initial pre-training stage. 
This implies lots of use-cases.
Personalized assistants: remembers user details, tone preferences, and past decisions; dynamic personalization without costly retrain cycles.
Enterprise adoption: lawyers, analysts, and researchers can inject firm-specific style, briefs, and templates directly into the model behavior, removing brittle RAG engineering and reducing hallucinations on domain content.
Operational efficiency: continuous improvement as the LUT accumulates corrections — the model becomes better at routine tasks (email, code, summarization) with tiny incremental costs.
Competitive cost structure: lower compute and infra spend vs fine-tuning and RAG, enabling attractive margins for a hosted personalization layer or enterprise on-prem product.
True AGI requires models that can continuously learn and LUT based architectures take us a step closer to large models with the ability to “learn on the fly”, improving and personalizing responses with more interactions.
Evidence & current results
Widespread benchmarking across small models (1.6M → 16M params) shows perplexity reductions of ~15–40% when retrained on specific data.
Practical update cost: seconds for thousands of tokens (user-provided).
Note: retrieval-style benchmarks (large-scale retrieval accuracy) will require larger base models for fully representative results; current POC demonstrates strong signal that LUTs meaningfully steer logits when adapted to domain data.
These numbers show that this approach can vastly improve a model's performance when retrained on specific data. 

Roadmap (high level)
0–3 months: Hardening prototype, integration with 1 medium-sized base model, build pilot UI + update API.
3–6 months: Run enterprise pilots (legal, fintech), measure task-level metrics, optimize latency and compression.
6–12 months: Launch hosted LUT API, partner with model providers, begin IP filings and initial monetization.
Business model & go-to-market
Wedge product (Tier 1): Personalized assistants for power users (developer tools, content creators) — low friction, quick value.
Enterprise (Tier 2): Vertical pilots (legal, consulting, finance) — private on-prem or VPC deployment with SLA and compliance features (audit logs, access controls).
Platform play (Tier 3): Offer LUT as an infra layer / API that integrates with existing LLMs (partner with major model providers / model hosting platforms). Monetize via subscriptions, per-update pricing, and enterprise licensing.
Early customers: law firms and financial analysts (high value per personalization + privacy demand).




================================================================================
FILE: InvestorQA.docx
================================================================================


Investor Q&A – Lookup-Table Augmented Transformers
Q1. This sounds really simple — why hasn’t anyone else done it?
A1. At first glance it looks trivial, but the practical implementation is not: deciding where to insert the table in the transformer, stabilizing training through logit inversion, and managing similarity metrics are all non-trivial challenges. Researchers and industry labs have been path-dependent on scaling canonical transformers, so even elegant low-complexity ideas like this get overlooked. The simplicity is actually the strength — it means large gains with minimal engineering overhead.
Q2. What’s the core benefit compared to standard transformers?
A2. Being able to be continuously trainable allows the model to adapt, pick up preferences and get better over-time. We believe this unlocks use cases in personalized models: personal GPTs, AI tutors and expert models(Law, health, etc). This could also be a step towards smarter models- if we are able to continuously train these agents- giving them an effectively infinite context window it would be reasonable to predict increased intelligence over-time.
Q3. Is this defensible IP? Couldn’t others just copy it once they see it works?
A3. We would keep it as a trade secret.
Q4. How does this scale with model size? Does it only work for small models?
A4. To be answered when we have trained a 50M param model- should have the same returns in theory.
Q5. What are the compute implications? Does it make training slower or cheaper?
A5. Training is the same since the LUTs are trained after the main pre-training phase. Slight latency at inference due to lookup operations but this can be optimized to negligible point.
Q6. What are the risks or limitations of this approach?
A6. Large lookup tables cause latency but this can be offset with faster lookup algorithms (FAISS, etc) and pruning of the tables. We also risk overfitting but in tests this was not an issue.
Q7. What’s the commercialization path? How does this become a business?
A7. 
Q8. Why you? Why not a larger lab?
A8. Because larger labs are optimized for brute-force scaling, not lean architectural innovation. This is a breakthrough that thrives in a small, agile environment before scaling to mainstream adoption.

Q9. Who are your competitors, and how does this compare?
A9. RAG, loRA/ finetunning are the closest cousins to this approach.

Q10. What’s the evidence this works beyond toy benchmarks?
A10. perplexity drops, Topic shift results

Q11. How big is the market opportunity?
A11. Huge

Q12. What’s your ask? How much capital are you raising and why now?
A12. To be answered



================================================================================
FILE: List of potential Accelerators_ VCs.docx
================================================================================


List of potential Accelerators/ VCs

Accelerators
https://www.antler.co/apply?utm_source=chatgpt.com
Y combinator, https://apply.ycombinator.com/
Techstars london
Entrepreneur First
Founders Factory
VCs
Look AI Venture
Balderton Capital, https://www.balderton.com/team/, https://www.balderton.com/team/zoe-mohl/
Atomico
Bessemer Venture Partners
Andreessen Horowitz (a16z) 


================================================================================
FILE: Memory augmented Large Language Models.pptx
================================================================================





================================================================================
FILE: Use-cases.docx
================================================================================


Use-cases

Personalized GPTs

We envision an interface built around two models:
Main model – a lookup-table-based LLM that serves as the persistent memory and primary interaction layer.
Trainer model – a current state-of-the-art LLM used for refining and fine-tuning inputs.
The user interface resembles familiar chat systems (e.g., ChatGPT, Claude, Gemini): a simple conversational window for asking questions and receiving responses.
The key differentiator is the “Teach the model” feature. At any point, the user can click this button, which opens a dedicated window where they can provide new information or corrections. This data is immediately integrated into the LUT, effectively fine-tuning the main model in real time.
Because the LUT is persistent, all future generations automatically account for what the user has taught the system — creating a continuously personalized and adaptive model experience.



================================================================================
FILE: Application common questions.docx
================================================================================


Application common questions

Technical problem
A key weakness of LLMs is that they lack the ability to be continuously and instantly trained, the way humans naturally learn. This is a fundamentally hard problem: backpropagation, by design, isn’t suited for continuous training. It’s extremely compute-intensive and prone to issues like catastrophic forgetting, meaning that simply throwing more computational power at the problem won’t fix it. I have been working on this issue for the last six months making significant head-way to the point where I feel ready to start to commercialize it.

Idea
Current language models such as ChatGPT, Claude and Gemini have been wildly successful but we believe that there is a fundamental issue with these models. They cannot by nature be continuously trained and learn like humans do. Sure we can bolt-on rag systems but this approach does not fix the underlying problem, rather puts duct tape around it. Imagine a continuously learning personalization layer that adapts to users and enterprises without full retraining costs, improving accuracy, efficiency, and cost-effectiveness across tasks while reducing infrastructure and RAG complexity. Market potential- this idea will apply to anyone who uses LLMs such as ChatGPT and who wants to have a personalized experience with a model that learns and grows with/from them.

Bio
